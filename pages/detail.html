<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' width='16' height='16'><text x='0' y='12' font-size='12'>📋</text></svg>">
    <title>Content details</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../CSS/style.css"> <!-- 引入外部CSS -->
    <link href="https://cdn.jsdelivr.net/npm/prismjs@1.24.0/themes/prism.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.24.0/prism.js"></script>
</head>
<body>
    <!-- 侧边栏 -->
    <div class="sidebar">
        <img src="../imgs/lefttop_logo.png" alt="Logo">
        <a href="../index.html">⭐ Introduction</a>
        <a href="detail.html" class="active">📋 Theme & Topic</a>
        <!-- <a href="timeline.html">📅 Time arrangement</a> -->
        <a href="call.html">🖊️ Call for papers</a>
        <a href="organizers.html">🧑‍🤝‍🧑 Organizers & PC</a>
        <a href="talk.html">🔗 Talk Details & Schedule</a>
    </div>

    <!-- 内容部分 -->
    <div class="content">
        <div class="container">
            <!-- 顶部标题 -->
            <div class="header">
                <h1>📋 Theme & Topic</h1>
            </div>

            <!-- 任务内容 -->
            <div class="section">
                <h3>Theme:</h3>
                <ul class="task-list">
                    The <b>“Frontiers in Graph Machine Learning for the Large Model Era”</b> workshop focuses on advancing GML in the context of large models. It explores how structured relational data and graph representations can enhance reasoning, generalization, and interpretability in modern AI systems.
                </ul>
            </div>

            <div class="section">
                <h3>Topics of Interest: </h3>
                The workshop emphasizes <b>how large models, especially LLMs, can assist GML</b>, such as improving node classification, link prediction, and graph generation in low-resource or few-shot scenarios. We welcome work on using prompt tuning, instruction tuning, and in-context learning for graph tasks, as well as LLM-assisted data augmentation. We also explore <b>hybrid methods that integrate graph data with foundation models</b>, such as using knowledge graphs to guide representation learning.
                <br>We invite contributions that address <b>theoretical foundations, interpretability, and practical applications</b> of GML in the large model era. Topics include graph-structured explanations, graph structure alignment with LLM latent representations, and new paradigms for learning on complex graphs with LLMs. Application areas of interest include scientific discovery, knowledge graph completion, recommendation, and graph-based question answering, as well as <b>new benchmarks and tools</b> for evaluating LLM-augmented graph learning.
            </div>
    </div>
</body>
</html>